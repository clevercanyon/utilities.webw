/**
 * Utilities.
 *
 * @note PLEASE DO NOT EDIT THIS FILE!
 * @note This entire file will be updated automatically.
 * @note Instead of editing here, please review <https://github.com/clevercanyon/skeleton>.
 */

import { Octokit as OctokitCore } from '@octokit/core';
import { paginateRest as OctokitPluginPaginateRest } from '@octokit/plugin-paginate-rest';
import sodium from 'libsodium-wrappers';
import fs from 'node:fs';
import fsp from 'node:fs/promises';
import os from 'node:os';
import path from 'node:path';
import { $chalk, $cmd, $dotenv, $fs, $prettier } from '../../../../node_modules/@clevercanyon/utilities.node/dist/index.js';
import { $is, $json, $obj, $obp, $str, $url, $version } from '../../../../node_modules/@clevercanyon/utilities/dist/index.js';
import nodeVersion from './node-version.mjs';

const __dirname = $fs.imuDirname(import.meta.url);
const binDir = path.resolve(__dirname, '..');
const projDir = path.resolve(__dirname, '../../../..');

const { pkgFile, pkgName, pkgPrivate, pkgBuildAppType } = (() => {
    const pkgFile = path.resolve(projDir, './package.json');

    if (!fs.existsSync(pkgFile)) {
        throw new Error('u: Missing `./package.json`.');
    }
    const pkg = $json.parse(fs.readFileSync(pkgFile).toString());

    if (!$is.plainObject(pkg)) {
        throw new Error('u: Unable to parse `./package.json`.');
    }
    const pkgName = $obp.get(pkg, 'name', '');
    const pkgPrivate = $obp.get(pkg, 'private');
    const pkgBuildAppType = $obp.get(pkg, 'config.c10n.&.build.appType', '');

    return { pkgFile, pkgName, pkgPrivate, pkgBuildAppType };
})();
const Octokit = OctokitCore.plugin(OctokitPluginPaginateRest);
const octokit = new Octokit({ auth: process.env.USER_GITHUB_TOKEN || '' });

const githubConfigVersion = '1.0.9'; // Bump when config changes in routines below.
const githubEnvsVersion = '1.0.9'; // Bump when environments change in routines below.
const npmjsConfigVersion = '1.0.9'; // Bump when config changes in routines below.

const c10nLogo = path.resolve(__dirname, '../../assets/brands/c10n/logo.png');

/**
 * Utilities.
 */
export default class u {
    /**
     * Static props.
     */

    static s = {}; // Initialize.

    /**
     * Synchronous utilities.
     */

    /*
     * Output utilities.
     */

    static log(...args) {
        return console.log(...args);
    }

    /**
     * Asynchronous utilities.
     */

    /*
     * User environment var utilities.
     */

    static async propagateUserEnvVars() {
        process.env.NPM_TOKEN = process.env.USER_NPM_TOKEN || '';
        process.env.GH_TOKEN = process.env.USER_GITHUB_TOKEN || '';
        process.env.GITHUB_TOKEN = process.env.USER_GITHUB_TOKEN || '';
        process.env.CLOUDFLARE_API_TOKEN = process.env.USER_CLOUDFLARE_TOKEN || '';
    }

    /*
     * TTY utilities.
     */

    static async isInteractive() {
        const isTTY = process.stdout.isTTY || 'true' === process.env.PARENT_IS_TTY ? true : false;
        return isTTY && process.env.TERM && 'dumb' !== process.env.TERM && 'true' !== process.env.CI && true !== process.env.CI;
    }

    /**
     * Spawn utilities.
     */

    static async spawn(cmd, args = [], opts = {}) {
        return await $cmd.spawn(cmd, args, {
            cwd: projDir,
            stdio: 'pipe',
            env: {
                ...process.env, // Parent TTY assists {@see isInteractive()}.
                PARENT_IS_TTY: process.stdout.isTTY || process.env.PARENT_IS_TTY ? 'true' : 'false',
            },
            ...opts,
        });
    }

    /*
     * Pkg utilities.
     */

    static async pkg(file = pkgFile) {
        if (!fs.existsSync(file)) {
            throw new Error('u.pkg: Missing `' + file + '`.');
        }
        const pkg = $json.parse(fs.readFileSync(file).toString());

        if (!$is.plainObject(pkg)) {
            throw new Error('u.pkg: Unable to parse `' + file + '`.');
        }
        return pkg; // JSON object data.
    }

    static async depPkg(dependency) {
        return u.pkg(path.resolve(projDir, './node_modules', dependency, './package.json'));
    }

    static async isPkgName(name) {
        return name === pkgName; // True if is current package name.
    }

    static async isPkgFork() {
        return pkgName.endsWith('.fork'); // True if current package is a fork.
    }

    static async isPkgSkeleton() {
        return 'skeleton' === pkgName || pkgName.startsWith('skeleton.');
    }

    static async pkgIncrementVersion(opts = { dryRun: false }) {
        const pkg = await u.pkg(); // Parses current `./package.json` file.

        const origVersion = String(pkg.version || '');
        let version = origVersion || '0.0.0';

        if (!$version.isValid(version)) {
            throw new Error('u.pkgIncrementVersion: Not a semantic version: `' + origVersion + '`.');
        }
        const isVersionPrerelease = $version.prerelease(version) ? true : false;
        version = $version.increment(version, isVersionPrerelease ? 'prerelease' : 'patch');

        if (!version /* Catch increment failures. */) {
            throw new Error('u.pkgIncrementVersion: Failed to increment version: `' + origVersion + '`.');
        }
        if (!opts.dryRun) {
            await u.updatePkg({ version });
        }
    }

    static async updatePkg(propsOrPath = {}, value = undefined, separator = '.') {
        const pkg = await u.pkg(); // Parses current `./package.json` file.

        if ($is.string(propsOrPath)) {
            const path = propsOrPath;
            $obp.set(pkg, path, value, separator);
            //
        } else if ($is.plainObject(propsOrPath)) {
            const props = propsOrPath; // Object properties.
            $obj.patchDeep(pkg, props); // Potentially declarative ops.
        } else {
            throw new Error('u.updatePkg: Invalid arguments.');
        }
        const updatesFile = path.resolve(projDir, './dev/.files/bin/updater/data/_package.json/updates.json');
        const updates = $json.parse((await fsp.readFile(updatesFile)).toString());

        if (!$is.plainObject(updates)) {
            throw new Error('u.updatePkg: Unable to parse `' + updatesFile + '`.');
        }
        if (await u.isPkgFork()) {
            if (updates.$ꓺdefaults?.imports) updates.$ꓺdefaults.imports = {};
        }
        if (Object.hasOwn(updates.$ꓺset?.engines || {}, 'node')) {
            updates.$ꓺset.engines.node = []; // Initialize.
            if (nodeVersion.previous) updates.$ꓺset.engines.node.push(nodeVersion.previous);
            if (nodeVersion.current) updates.$ꓺset.engines.node.push(nodeVersion.current);
            if (nodeVersion.forwardCompat.length) updates.$ꓺset.engines.node = updates.$ꓺset.engines.node.concat(nodeVersion.forwardCompat);
            updates.$ꓺset.engines.node = (updates.$ꓺset.engines.node.length ? '^' : '') + updates.$ꓺset.engines.node.join(' || ^');
        }
        if (Object.hasOwn(updates.$ꓺset?.engines || {}, 'npm')) {
            updates.$ꓺset.engines.npm = []; // Initialize.
            if (nodeVersion.npm.previous) updates.$ꓺset.engines.npm.push(nodeVersion.npm.previous);
            if (nodeVersion.npm.current) updates.$ꓺset.engines.npm.push(nodeVersion.npm.current);
            if (nodeVersion.npm.forwardCompat.length) updates.$ꓺset.engines.npm = updates.$ꓺset.engines.npm.concat(nodeVersion.npm.forwardCompat);
            updates.$ꓺset.engines.npm = (updates.$ꓺset.engines.npm.length ? '^' : '') + updates.$ꓺset.engines.npm.join(' || ^');
        }
        if (await u.isPkgName('@clevercanyon/dev-deps')) {
            if (updates.$ꓺdefaults?.['devDependenciesꓺ@clevercanyon/dev-deps']) {
                delete updates.$ꓺdefaults['devDependenciesꓺ@clevercanyon/dev-deps'];
            }
            if ($is.array(updates.$ꓺunset)) {
                updates.$ꓺunset.push('devDependenciesꓺ@clevercanyon/dev-deps');
            } else {
                updates.$ꓺunset = ['devDependenciesꓺ@clevercanyon/dev-deps'];
            }
        }
        $obj.patchDeep(pkg, updates); // Potentially declarative ops.
        const prettierConfig = { ...(await $prettier.resolveConfig(pkgFile)), parser: 'json' };
        await fsp.writeFile(pkgFile, await $prettier.format($json.stringify(pkg, { pretty: true }), prettierConfig));
    }

    /*
     * Git utilities.
     */

    static async isGitRepo() {
        try {
            return 'true' === String(await u.spawn('git', ['rev-parse', '--is-inside-work-tree'], { quiet: true })).trim();
        } catch {
            return false;
        }
    }

    static async isGitRepoDirty() {
        return '' !== (await u.gitStatus({ short: true }));
    }

    static async isGitRepoOriginGitHub() {
        try {
            const { owner, repo } = await u.githubOrigin();
            return owner && repo ? true : false;
        } catch {
            return false;
        }
    }

    static async gitStatus(opts = { short: false }) {
        return String(await u.spawn('git', ['status', ...(opts.short ? ['--short'] : []), '--porcelain'], { quiet: true })).trim();
    }

    static async gitCurrentBranch() {
        const branch = String(await u.spawn('git', ['symbolic-ref', '--short', '--quiet', 'HEAD'], { quiet: true })).trim();

        if (!branch) {
            // In the case of being on a tag or a specific commit SHA.
            throw new Error('u.gitCurrentBranch: Not currently on any git branch.');
        }
        return branch;
    }

    static async gitAddCommitTagPush(message) {
        await u.gitAddCommitTag(message);
        await u.gitPush();
    }

    static async gitAddCommitPush(message) {
        await u.gitAddCommit(message);
        await u.gitPush();
    }

    static async gitAddCommitTag(message) {
        await u.gitAddCommit(message);
        await u.gitTag(message);
    }

    static async gitAddCommit(message) {
        await u.spawn('git', ['add', '--all']);
        await u.spawn('git', ['commit', '--message', message + (/\]$/u.test(message) ? '' : ' ') + '[robotic]']);
    }

    static async gitTag(message) {
        const pkg = await u.pkg(); // Parses current `./package.json` file.

        if (!pkg.version) {
            throw new Error('u.gitTag: Package version is empty.');
        }
        await u.spawn('git', ['tag', '--annotate', 'v' + pkg.version, '--message', message + (/\]$/u.test(message) ? '' : ' ') + '[robotic]']);
    }

    static async gitPush() {
        await u.spawn('git', ['push', '--set-upstream', 'origin', await u.gitCurrentBranch()]);
        await u.spawn('git', ['push', 'origin', '--tags']);
    }

    static async gitLocalRepoSHA(repoDir, branch) {
        return String(await u.spawn('git', ['rev-parse', branch], { cwd: repoDir, quiet: true }))
            .trim()
            .toLowerCase();
    }

    static async gitRemoteRepoSHA(repoURI, branch) {
        return String(await u.spawn('git', ['ls-remote', repoURI, branch], { cwd: os.tmpdir(), quiet: true }))
            .trim()
            .toLowerCase()
            .split(/\s+/u)[0];
    }

    /**
     * Gist utilities.
     */

    static async gistGetJSON(user, gistId) {
        return await (await fetch('https://gist.github.com/' + $url.encode(user) + '/' + $url.encode(gistId) + '/raw')).json();
    }

    static async gistGetC10NUsers() {
        // <https://gist.github.com/jaswrks/0a1780dc08ac30824858bbbb86294c73>
        return await u.gistGetJSON('jaswrks', '0a1780dc08ac30824858bbbb86294c73');
    }

    static async gistGetC10NUser() {
        if (!process.env.USER_GITHUB_USERNAME) {
            return {}; // Not available.
        }
        const c10nUsers = await u.gistGetC10NUsers();
        const githubUsername = String(process.env.USER_GITHUB_USERNAME).replace(/^@/u, '').toLowerCase();

        let c10nUser = c10nUsers[githubUsername] || {};
        c10nUser = $is.plainObject(c10nUser) ? c10nUser : {};
        $obp.set(c10nUser, 'github.username', githubUsername);

        return c10nUser;
    }

    /*
     * GitHub utilities.
     */

    static async githubOrigin() {
        let m = null; // Initialize array of matches.
        const url = String(await u.spawn('git', ['remote', 'get-url', 'origin'], { quiet: true })).trim();

        if ((m = /^https?:\/\/github.com\/([^/]+)\/([^/]+?)(?:\.git)?$/iu.exec(url))) {
            return { owner: m[1], repo: m[2] };
        } else if ((m = /^git@github(?:\.com)?:([^/]+)\/([^/]+?)(?:\.git)?$/iu.exec(url))) {
            return { owner: m[1], repo: m[2] };
        }
        throw new Error('u.githubOrigin: Repo does not have a GitHub origin.');
    }

    static async githubReleaseTag() {
        const { owner, repo } = await u.githubOrigin();
        const distZipFile = path.resolve(projDir, './.~dist.zip');
        const pkg = await u.pkg(); // Parses current `./package.json` file.

        if (!pkg.version) {
            throw new Error('u.githubReleaseTag: Package version is empty.');
        }
        if ((await u.isViteBuild()) && !fs.existsSync(distZipFile)) {
            throw new Error('u.githubReleaseTag: Missing `./.~dist.zip` archive.');
        }
        const r = await octokit.request('POST /repos/{owner}/{repo}/releases', {
            owner,
            repo,

            name: 'v' + pkg.version,
            tag_name: 'v' + pkg.version,

            draft: false,
            generate_release_notes: true,
            prerelease: $version.prerelease(pkg.version) ? true : false,
        });
        if (!$is.object(r) || !$is.object(r.data) || !r.data.id || !r.data.upload_url) {
            throw new Error('u.githubReleaseTag: Failed to acquire GitHub release data.');
        }
        if ((await u.isViteBuild()) && fs.existsSync(distZipFile)) {
            await octokit.request({
                method: 'POST',
                url: r.data.upload_url,

                name: 'dist.zip',
                headers: {
                    'content-type': 'application/zip',
                    'content-length': fs.statSync(distZipFile).size,
                },
                data: fs.readFileSync(distZipFile),
            });
        }
    }

    static async githubCheckRepoOrgWideStandards(opts = { dryRun: false }) {
        const { owner, repo } = await u.githubOrigin();
        const repoData = await u._githubRepo();

        if ('Organization' !== repoData.owner?.type) {
            return; // Repo is not part of an organization.
        }
        if ('clevercanyon' !== repoData.organization?.login) {
            return; // Repo not in the `clevercanyon` organization.
        }
        if (!repoData.permissions?.admin) {
            return; // Current user’s permissions do not allow repo configuration.
        }
        const pkg = await u.pkg(); // Parses current `./package.json` file.

        if ($obp.get(pkg, 'config.c10n.&.github.configVersion') === githubConfigVersion) {
            u.log($chalk.gray('GitHub repo configuration is up-to-date @v' + githubConfigVersion + '.'));
            return; // Repo configuration version is already up-to-date.
        }
        if ('main' !== repoData.default_branch) {
            throw new Error('githubCheckRepoOrgWideStandards: Default branch at GitHub must be `main`.');
        }
        await u._githubEnsureRepoEnvs({ dryRun: opts.dryRun }); // Creates|deletes repo envs.

        const requiredLabels = {
            'bug report': {
                color: 'b60205',
                desc: 'Something isn’t working.',
            },
            'good first issue': {
                color: 'fef2c0',
                desc: 'Good first issue for newcomers.',
            },
            'question': {
                color: '0e8a16',
                desc: 'Something is being asked.',
            },
            'request': {
                color: '1d76db',
                desc: 'Something is being requested.',
            },
            'robotic': {
                color: 'eeeeee',
                desc: 'Something created robotically.',
            },
            'suggestion': {
                color: 'fbca04',
                desc: 'Something is being suggested.',
            },
        };
        const rulesets = {
            main: {
                name: 'main',
                target: 'branch',
                enforcement: 'active',
                conditions: { ref_name: { include: ['refs/heads/main'], exclude: [] } },
                rules: [
                    { type: 'creation' },
                    { type: 'deletion' },
                    { type: 'non_fast_forward' },
                    { type: 'required_signatures' },
                    { type: 'required_linear_history' },
                    { type: 'update', parameters: { update_allows_fetch_and_merge: true } },
                    { type: 'required_deployments', parameters: { required_deployment_environments: ['ci'] } },
                    {
                        type: 'pull_request',
                        parameters: {
                            require_code_owner_review: true,
                            require_last_push_approval: true,
                            required_approving_review_count: 1,
                            dismiss_stale_reviews_on_push: true,
                            required_review_thread_resolution: true,
                        },
                    },
                ],
                bypass_actors: [{ actor_id: 7256007 /* owners */, actor_type: 'Team', bypass_mode: 'always' }],
            },
        };
        const protectedBranches = {
            main: {
                lock_branch: false,
                block_creations: true,
                allow_deletions: false,
                allow_fork_syncing: false,
                allow_force_pushes: false,

                required_signatures: true,
                required_linear_history: true,
                required_conversation_resolution: true,
                required_status_checks: null, // We don't use.

                // required_deployment_environments: { environments: ['ci'] },
                // Deployments not currently implemented for branch protections via API.
                // In order to pull this off it has to be done through a ruleset.

                restrictions: { users: [], teams: ['owners'], apps: [] },
                required_pull_request_reviews: {
                    dismiss_stale_reviews: true,
                    require_code_owner_reviews: true,
                    required_approving_review_count: 1,
                    require_last_push_approval: true,
                    dismissal_restrictions: { users: [], teams: ['owners'], apps: [] },
                    bypass_pull_request_allowances: { users: [], teams: ['owners'], apps: [] },
                },
                enforce_admins: false, // No. Let's not get too crazy.
            },
        };
        const labels = $obj.assign({}, $obp.get(pkg, 'config.c10n.&.github.labels', {}), requiredLabels);
        const labelsToDelete = await u._githubRepoLabels(); // Current list of repo’s labels.

        const requiredTeams = { owners: 'admin', 'security-managers': 'pull' }; // No exceptions.
        const teams = $obj.assign({}, $obp.get(pkg, 'config.c10n.&.github.teams', {}), requiredTeams);
        const teamsToDelete = await u._githubRepoTeams(); // Current list of repo’s teams.

        const rulesetsToDelete = await u._githubRepoRulesets();
        const protectedBranchesToDelete = await u._githubRepoProtectedBranches();

        const defaultHomepage = 'https://github.com/' + $url.encode(owner) + '/' + $url.encode(repo) + '#readme';
        const defaultDescription = 'Another great project by @' + repoData.owner.login + '.';

        u.log($chalk.gray('Configuring GitHub repo using org-wide standards.'));
        if (!opts.dryRun) {
            await octokit.request('PATCH /repos/{owner}/{repo}', {
                owner,
                repo,

                has_wiki: true,
                has_issues: true,
                has_projects: true,
                has_discussions: true,
                has_downloads: true,

                allow_auto_merge: false,
                allow_squash_merge: true,
                allow_merge_commit: false,
                allow_rebase_merge: false,
                allow_update_branch: true,
                delete_branch_on_merge: true,
                web_commit_signoff_required: false,

                // allow_forking: false,
                // Not possible to configure forking via API ops.
                // Disabled for private repos at org level already.
                // Public repos are always forkable repos, no exceptions.

                ...(!repoData.private // Available for public repos only.
                    ? {
                          security_and_analysis: {
                              // advanced_security: { status: 'enabled' },
                              // Always on for public repos, and throws warning when attempting to enable.
                              // For private repos, these features are currently unavailable on the pro plan.

                              secret_scanning: { status: 'enabled' },
                              secret_scanning_push_protection: { status: 'enabled' },
                          },
                      }
                    : {}),
                merge_commit_title: 'MERGE_MESSAGE',
                merge_commit_message: 'PR_TITLE',

                squash_merge_commit_title: 'PR_TITLE',
                squash_merge_commit_message: 'COMMIT_MESSAGES',

                homepage: pkg.homepage || defaultHomepage,
                description: pkg.description || defaultDescription,

                is_template: await u.isPkgSkeleton(),
            });
            await octokit.request('PUT /repos/{owner}/{repo}/vulnerability-alerts', { owner, repo });
            await octokit.request('PUT /repos/{owner}/{repo}/automated-security-fixes', { owner, repo });

            if (!repoData.private /* Available for public repos only. */) {
                await octokit.request('PUT /repos/{owner}/{repo}/private-vulnerability-reporting', { owner, repo });
            }
        }

        for (const [labelName, labelData] of Object.entries(labels)) {
            if (labelsToDelete[labelName]) {
                delete labelsToDelete[labelName]; // Don't delete.

                u.log($chalk.gray('Updating `' + labelName + '` label in GitHub repo to `#' + labelData.color + '` color.'));
                if (!opts.dryRun) {
                    await octokit.request('PATCH /repos/{owner}/{repo}/labels/{labelName}', { owner, repo, labelName, ...labelData });
                }
            } else {
                u.log($chalk.gray('Adding `' + labelName + '` label to GitHub repo with `#' + labelData.color + '` color.'));
                if (!opts.dryRun) {
                    await octokit.request('POST /repos/{owner}/{repo}/labels', { owner, repo, name: labelName, ...labelData });
                }
            }
        }
        for (const [labelName, labelData] of Object.entries(labelsToDelete)) {
            u.log($chalk.gray('Deleting `' + labelName + '` (unused) label with `#' + labelData.color + '` color from GitHub repo.'));
            if (!opts.dryRun) {
                await octokit.request('DELETE /repos/{owner}/{repo}/labels/{labelName}', { owner, repo, labelName });
            }
        }

        for (const [teamSlug, permission] of Object.entries(teams)) {
            delete teamsToDelete[teamSlug]; // Don't delete.

            u.log($chalk.gray('Adding `' + teamSlug + '` team to GitHub repo with `' + permission + '` permission.'));
            if (!opts.dryRun) {
                await octokit.request('PUT /orgs/{org}/teams/{teamSlug}/repos/{owner}/{repo}', { org: owner, owner, repo, teamSlug, permission });
            }
        }
        for (const [teamSlug, teamData] of Object.entries(teamsToDelete)) {
            u.log($chalk.gray('Deleting `' + teamSlug + '` (unused) team with `' + teamData.permission + '` permission from GitHub repo.'));
            if (!opts.dryRun) {
                await octokit.request('DELETE /orgs/{org}/teams/{teamSlug}/repos/{owner}/{repo}', { org: owner, owner, repo, teamSlug });
            }
        }

        for (const [rulesetName, rulesetProtections] of Object.entries(rulesets)) {
            if (rulesetsToDelete[rulesetName]) {
                const rulesetId = rulesetsToDelete[rulesetName].id; // Needed below.
                delete rulesetsToDelete[rulesetName]; // Don't delete.

                u.log($chalk.gray('Updating `' + rulesetName + '` ruleset in GitHub repo.'));
                if (!opts.dryRun) {
                    await octokit.request('PUT /repos/{owner}/{repo}/rulesets/{rulesetId}', { owner, repo, rulesetId, ...rulesetProtections });
                }
            } else {
                u.log($chalk.gray('Adding `' + rulesetName + '` ruleset to GitHub repo.'));
                if (!opts.dryRun) {
                    await octokit.request('POST /repos/{owner}/{repo}/rulesets', { owner, repo, ...rulesetProtections });
                }
            }
        }
        for (const [rulesetName, rulesetData] of Object.entries(rulesetsToDelete)) {
            u.log($chalk.gray('Deleting `' + rulesetName + '` (unused) ruleset from GitHub repo.'));
            if (!opts.dryRun) {
                await octokit.request('DELETE /repos/{owner}/{repo}/rulesets/{rulesetId}', { owner, repo, rulesetId: rulesetData.id });
            }
        }

        for (const [branchName, branchProtections] of Object.entries(protectedBranches)) {
            delete protectedBranchesToDelete[branchName]; // Don't delete.

            u.log($chalk.gray('Protecting `' + branchName + '` branch in GitHub repo.'));
            if (!opts.dryRun) {
                await octokit.request('PUT /repos/{owner}/{repo}/branches/{branchName}/protection', { owner, repo, branchName, ...branchProtections });
            }
        }
        for (const [branchName] of Object.entries(protectedBranchesToDelete)) {
            u.log($chalk.gray('Deleting `' + branchName + '` (unused) branch protection in GitHub repo.'));
            if (!opts.dryRun) {
                await octokit.request('DELETE /repos/{owner}/{repo}/branches/{branchName}/protection', { owner, repo, branchName });
            }
        }

        if (!opts.dryRun) {
            await u.updatePkg('config.c10n.&.github.configVersion', githubConfigVersion);
        }
    }

    static async githubPushRepoEnvs(opts = { dryRun: false }) {
        const { id: repoId, ...repoData } = await u._githubRepo();

        if ('Organization' !== repoData.owner?.type) {
            return; // Repo is not part of an organization.
        }
        if ('clevercanyon' !== repoData.organization?.login) {
            return; // Repo not in the `clevercanyon` organization.
        }
        if (!repoData.permissions?.admin) {
            return; // Current user’s permissions do not allow.
        }
        const pkg = await u.pkg(); // Parses current `./package.json` file.

        if ($obp.get(pkg, 'config.c10n.&.github.envsVersion') === githubEnvsVersion) {
            u.log($chalk.gray('GitHub repo environments are up-to-date @v' + githubEnvsVersion + '.'));
            return; // Repo environments version is already up-to-date.
        }
        u.log($chalk.gray('Configuring GitHub repo environments using org-wide standards.'));

        const envFiles = await u.envFiles(); // All environment files.
        const envKeys = await u._envsExtractKeys(); // Dotenv Vault decryption keys.
        await u._githubEnsureRepoEnvs({ dryRun: opts.dryRun }); // Creates|deletes repo envs.

        for (const [envName] of Object.entries($obj.omit(envFiles, ['main']))) {
            const envSecretsToDelete = await u._githubRepoEnvSecrets(repoId, envName);

            for (const [envSecretName, envSecretValue] of Object.entries({
                ['USER_DOTENV_KEY_MAIN']: envKeys.main,
                ['USER_DOTENV_KEY_' + envName.toUpperCase()]: envKeys[envName],
            })) {
                delete envSecretsToDelete[envSecretName]; // Don't delete.
                const { envPublicKeyId, envPublicKey } = await u._githubRepoEnvPublicKey(repoId, envName);

                const encryptedEnvSecretValue = await sodium.ready.then(() => {
                    const sodiumKey = sodium.from_base64(envPublicKey, sodium.base64_variants.ORIGINAL);
                    return sodium.to_base64(sodium.crypto_box_seal(sodium.from_string(envSecretValue), sodiumKey), sodium.base64_variants.ORIGINAL);
                });
                u.log($chalk.gray('Updating `' + envSecretName + '` secret in `' + envName + '` repo env at GitHub.'));
                if (!opts.dryRun) {
                    await octokit.request('PUT /repositories/{repoId}/environments/{envName}/secrets/{envSecretName}', {
                        repoId,
                        envName,
                        envSecretName,
                        key_id: envPublicKeyId,
                        encrypted_value: encryptedEnvSecretValue,
                    });
                }
            }
            for (const [envSecretName] of Object.entries(envSecretsToDelete)) {
                u.log($chalk.gray('Deleting `' + envSecretName + '` (unused) secret in `' + envName + '` repo env at GitHub.'));
                if (!opts.dryRun) {
                    await octokit.request('DELETE /repositories/{repoId}/environments/{envName}/secrets/{envSecretName}', { repoId, envName, envSecretName });
                }
            }
        }
        if (!opts.dryRun) {
            await u.updatePkg('config.c10n.&.github.envsVersion', githubEnvsVersion);
        }
    }

    static async _githubRepo() {
        const { owner, repo } = await u.githubOrigin();
        const r = await octokit.request('GET /repos/{owner}/{repo}', { owner, repo });

        if (!$is.object(r) || !$is.object(r.data) || !r.data.id) {
            throw new Error('u._githubRepo: Failed to acquire GitHub repository’s data.');
        }
        return r.data;
    }

    static async _githubRepoLabels() {
        const labels = {}; // Initialize.
        const { owner, repo } = await u.githubOrigin();
        const i6r = octokit.paginate.iterator('GET /repos/{owner}/{repo}/labels{?per_page}', { owner, repo, per_page: 100 });

        if (!$is.object(i6r)) {
            throw new Error('u._githubRepoLabels: Failed to acquire GitHub repository’s labels.');
        }
        for await (const { data } of i6r) {
            for (const label of data) {
                if (!$is.object(label) || !label.name) {
                    throw new Error('u._githubRepoLabels: Failed to acquire GitHub repository’s label data.');
                }
                labels[label.name] = label;
            }
        }
        return labels;
    }

    static async _githubRepoTeams() {
        const repoTeams = {}; // Initialize.
        const { owner, repo } = await u.githubOrigin();
        const i6r = octokit.paginate.iterator('GET /repos/{owner}/{repo}/teams{?per_page}', { owner, repo, per_page: 100 });

        if (!$is.object(i6r)) {
            throw new Error('u._githubRepoTeams: Failed to acquire GitHub repository’s teams.');
        }
        for await (const { data } of i6r) {
            for (const repoTeam of data) {
                if (!$is.object(repoTeam) || !repoTeam.slug) {
                    throw new Error('u._githubRepoTeams: Failed to acquire a GitHub repo team’s data.');
                }
                repoTeams[repoTeam.slug] = repoTeam;
            }
        }
        return repoTeams;
    }

    static async _githubRepoProtectedBranches() {
        const repoProtectedBranches = {};
        const { owner, repo } = await u.githubOrigin();
        const i6r = octokit.paginate.iterator('GET /repos/{owner}/{repo}/branches{?protected,per_page}', { owner, repo, protected: true, per_page: 100 });

        if (!$is.object(i6r)) {
            throw new Error('u._githubRepoProtectedBranches: Failed to acquire GitHub repository’s protected branches.');
        }
        for await (const { data } of i6r) {
            for (const repoProtectedBranch of data) {
                if (!$is.object(repoProtectedBranch) || !repoProtectedBranch.name) {
                    throw new Error('u._githubRepoProtectedBranches: Failed to acquire a GitHub repository’s protected branch data.');
                }
                repoProtectedBranches[repoProtectedBranch.name] = repoProtectedBranch;
            }
        }
        return repoProtectedBranches;
    }

    static async _githubRepoRulesets() {
        const repoRulesets = {};
        const { owner, repo } = await u.githubOrigin();
        const i6r = octokit.paginate.iterator('GET /repos/{owner}/{repo}/rulesets{?includes_parents,per_page}', { owner, repo, includes_parents: false, per_page: 100 });

        if (!$is.object(i6r)) {
            throw new Error('u._githubRepoRulesets: Failed to acquire GitHub repository’s rulesets.');
        }
        for await (const { data } of i6r) {
            for (const repoRuleset of data) {
                if (!$is.object(repoRuleset) || !repoRuleset.name) {
                    throw new Error('u._githubRepoRulesets: Failed to acquire a GitHub repository’s ruleset data.');
                }
                repoRulesets[repoRuleset.name] = repoRuleset;
            }
        }
        return repoRulesets;
    }

    static async _githubRepoEnvs() {
        const envs = {}; // Initialize.
        const { owner, repo } = await u.githubOrigin();
        const i6r = octokit.paginate.iterator('GET /repos/{owner}/{repo}/environments{?per_page}', { owner, repo, per_page: 100 });

        if (!$is.object(i6r)) {
            throw new Error('u._githubRepoEnvs: Failed to acquire GitHub repository’s environments.');
        }
        for await (const { data } of i6r) {
            for (const env of data) {
                if (!$is.object(env) || !env.name) {
                    throw new Error('u._githubRepoEnvs: Failed to acquire GitHub repository’s environment data.');
                }
                envs[env.name] = env;
            }
        }
        return envs;
    }

    static async _githubRepoEnvPublicKey(repoId, envName) {
        const r = await octokit.request('GET /repositories/{repoId}/environments/{envName}/secrets/public-key', { repoId, envName });

        if (!$is.object(r) || !$is.object(r.data) || !r.data.key_id || !r.data.key) {
            throw new Error('u._githubRepoEnvPublicKey: Failed to acquire GitHub repository env’s public key.');
        }
        return { envPublicKeyId: r.data.key_id, envPublicKey: r.data.key };
    }

    static async _githubRepoEnvSecrets(repoId, envName) {
        const envSecrets = {}; // Initialize.
        const i6r = octokit.paginate.iterator('GET /repositories/{repoId}/environments/{envName}/secrets{?per_page}', { repoId, envName, per_page: 100 });

        if (!$is.object(i6r)) {
            throw new Error('u._githubRepoEnvSecrets: Failed to acquire GitHub repository’s secrets for an environment.');
        }
        for await (const { data } of i6r) {
            for (const envSecret of data) {
                if (!$is.object(envSecret) || !envSecret.name) {
                    throw new Error('u._githubRepoEnvSecrets: Failed to acquire GitHub repository’s secret data for an environment.');
                }
                envSecrets[envSecret.name] = envSecret;
            }
        }
        return envSecrets;
    }

    static async _githubRepoEnvBranchPolicies(envName) {
        const envBranchPolicies = {}; // Initialize.
        const { owner, repo } = await u.githubOrigin();
        const i6r = octokit.paginate.iterator('GET /repos/{owner}/{repo}/environments/{envName}/deployment-branch-policies{?per_page}', { owner, repo, envName, per_page: 100 });

        if (!$is.object(i6r)) {
            throw new Error('u._githubRepoEnvBranchPolicies: Failed to acquire GitHub repository’s branch policies for an environment.');
        }
        for await (const { data } of i6r) {
            for (const envBranchPolicy of data) {
                if (!$is.object(envBranchPolicy) || !envBranchPolicy.name) {
                    throw new Error('u._githubRepoEnvBranchPolicies: Failed to acquire GitHub repository’s branch policy data for an environment.');
                }
                envBranchPolicies[envBranchPolicy.name] = envBranchPolicy;
            }
        }
        return envBranchPolicies;
    }

    static async _githubEnsureRepoEnvs(opts = { dryRun: false }) {
        if (u.s._githubRepoEnvsEnsured) return;
        u.s._githubRepoEnvsEnsured = true; // Once only.

        const envFiles = await u.envFiles();
        const { owner, repo } = await u.githubOrigin();
        const repoEnvs = await u._githubRepoEnvs();
        const repoEnvsToDelete = $obj.assign({}, repoEnvs);

        for (const [envName] of Object.entries($obj.omit(envFiles, ['main']))) {
            delete repoEnvsToDelete[envName]; // Don't delete.

            if (repoEnvs[envName]) {
                u.log($chalk.gray('Updating `' + envName + '` repo env at GitHub.'));
            } else {
                u.log($chalk.gray('Creating `' + envName + '` repo env at GitHub.'));
            }
            if (!opts.dryRun) {
                await octokit.request('PUT /repos/{owner}/{repo}/environments/{envName}', {
                    owner,
                    repo,
                    envName,
                    deployment_branch_policy: {
                        protected_branches: false,
                        custom_branch_policies: true,
                    },
                });
                const repoEnvBranchPolicies = await u._githubRepoEnvBranchPolicies(envName);
                const repoEnvBranchPoliciesToDelete = $obj.assign({}, repoEnvBranchPolicies);

                for (const repoEnvBranchPolicyName of [...('prod' === envName ? ['main'] : [])]) {
                    delete repoEnvBranchPoliciesToDelete[repoEnvBranchPolicyName]; // Don't delete.

                    if (!repoEnvBranchPolicies[repoEnvBranchPolicyName]) {
                        u.log($chalk.gray('Creating `' + repoEnvBranchPolicyName + '` branch policy for `' + envName + '` repo env at GitHub.'));
                        if (!opts.dryRun) {
                            await octokit.request('POST /repos/{owner}/{repo}/environments/{envName}/deployment-branch-policies', {
                                owner,
                                repo,
                                envName,
                                name: repoEnvBranchPolicyName,
                            });
                        }
                    }
                }
                for (const [repoEnvBranchPolicyName, repoEnvBranchPolicy] of Object.entries(repoEnvBranchPoliciesToDelete)) {
                    u.log($chalk.gray('Deleting `' + repoEnvBranchPolicyName + '` (unused) branch policy for `' + envName + '` repo env at GitHub.'));
                    if (!opts.dryRun) {
                        await octokit.request('DELETE /repos/{owner}/{repo}/environments/{envName}/deployment-branch-policies/{branchPolicyId}', {
                            owner,
                            repo,
                            envName,
                            branchPolicyId: repoEnvBranchPolicy.id,
                        });
                    }
                }
            }
        }
        for (const [envName] of Object.entries(repoEnvsToDelete)) {
            u.log($chalk.gray('Deleting `' + envName + '` (unused) repo env at GitHub.'));
            if (!opts.dryRun) {
                await octokit.request('DELETE /repos/{owner}/{repo}/environments/{envName}', { owner, repo, envName });
            }
        }
    }

    /*
     * Env utilities.
     */

    static async envFiles() {
        return {
            main: path.resolve(projDir, './dev/.envs/.env'),
            dev: path.resolve(projDir, './dev/.envs/.env.dev'),
            ci: path.resolve(projDir, './dev/.envs/.env.ci'),
            stage: path.resolve(projDir, './dev/.envs/.env.stage'),
            prod: path.resolve(projDir, './dev/.envs/.env.prod'),
        };
    }

    static async isEnvsVault() {
        return fs.existsSync(path.resolve(projDir, './.env.vault'));
    }

    static async envsPush(opts = { dryRun: false }) {
        const envFiles = await u.envFiles();

        for (const [envName, envFile] of Object.entries(envFiles)) {
            if (!fs.existsSync(envFile)) {
                u.log($chalk.gray('Creating file for `' + envName + '` env.'));
                if (!opts.dryRun) {
                    await fsp.mkdir(path.dirname(envFile), { recursive: true });
                    await fsp.writeFile(envFile, '# ' + envName);
                }
            }
            u.log($chalk.gray('Pushing `' + envName + '` env to Dotenv Vault.'));
            if (!opts.dryRun) {
                await u.spawn('npx', ['dotenv-vault', 'push', envName, envFile, '--yes']);
            }
        }
        u.log($chalk.gray('Encrypting all envs using latest Dotenv Vault data.'));
        if (!opts.dryRun) {
            await u.spawn('npx', ['dotenv-vault', 'build', '--yes']);
        }
        if ((await u.isGitRepo()) && (await u.isGitRepoOriginGitHub())) {
            await u.githubPushRepoEnvs({ dryRun: opts.dryRun });
        }
    }

    static async envsPull(opts = { dryRun: false }) {
        const envFiles = await u.envFiles();

        for (const [envName, envFile] of Object.entries(envFiles)) {
            u.log($chalk.gray('Pulling `' + envName + '` env from Dotenv Vault.'));
            if (!opts.dryRun) {
                await fsp.mkdir(path.dirname(envFile), { recursive: true });
                await u.spawn('npx', ['dotenv-vault', 'pull', envName, envFile, '--yes']);
                await fsp.rm(envFile + '.previous', { force: true });
            }
        }
    }

    static async envsKeys(opts = { dryRun: false }) {
        u.log($chalk.gray('Getting all Dotenv Vault keys.'));
        if (!opts.dryRun) {
            await u.spawn('npx', ['dotenv-vault', 'keys', '--yes']);
        }
    }

    static async envsEncrypt(opts = { dryRun: false }) {
        u.log($chalk.gray('Building Dotenv Vault; i.e., encrypting all envs.'));
        if (!opts.dryRun) {
            await u.spawn('npx', ['dotenv-vault', 'build', '--yes']);
        }
    }

    static async envsDecrypt(opts = { keys: [], dryRun: false }) {
        const envFiles = await u.envFiles();

        for (const key of opts.keys) {
            const envName = key.split('?')[1]?.split('=')[1] || '';
            const envFile = envFiles[envName] || '';

            if (!envName || !envFile) {
                throw new Error('u.envsDecrypt: Invalid Dotenv Vault decryption key: `' + key + '`.');
            }
            u.log($chalk.gray('Decrypting `' + envName + '` env using Dotenv Vault key.'));
            if (!opts.dryRun) {
                // Note: this doesn’t leak our environment variables, but it does leak all of the
                // variables in `./.env.vault`, because of the way it is processed internally by dotenv.
                // Issue opened at dotenv regarding the problem; {@see https://o5p.me/DBbi7j}.
                const env = $dotenv.$._parseVault({
                    DOTENV_KEY: key, // Pass explicitly.
                    path: path.resolve(projDir, './.env.vault'),
                });
                await fsp.mkdir(path.dirname(envFile), { recursive: true });
                await fsp.writeFile(envFile, await u._envToProps(envName, env));
            }
        }
    }

    static async envsInstallOrDecrypt(opts = { mode: 'prod' }) {
        if (!(await u.isInteractive()) /* Use keys. */) {
            const env = process.env; // Shorter reference.

            if (!env.USER_DOTENV_KEY_MAIN) {
                throw new Error('u.envsInstallOrDecrypt: Missing `USER_DOTENV_KEY_MAIN` environment variable.');
            }
            const keys = [env.USER_DOTENV_KEY_MAIN];

            if ('dev' === opts.mode) {
                if (!env.USER_DOTENV_KEY_DEV) {
                    throw new Error('u.envsInstallOrDecrypt: Missing `USER_DOTENV_KEY_DEV` environment variable.');
                }
                keys.push(env.USER_DOTENV_KEY_DEV);
                //
            } else if ('ci' === opts.mode) {
                if (!env.USER_DOTENV_KEY_CI) {
                    throw new Error('u.envsInstallOrDecrypt: Missing `USER_DOTENV_KEY_CI` environment variable.');
                }
                keys.push(env.USER_DOTENV_KEY_CI);
                //
            } else if ('stage' === opts.mode) {
                if (!env.USER_DOTENV_KEY_STAGE) {
                    throw new Error('u.envsInstallOrDecrypt: Missing `USER_DOTENV_KEY_STAGE` environment variable.');
                }
                keys.push(env.USER_DOTENV_KEY_STAGE);
                //
            } else if ('prod' === opts.mode) {
                if (!env.USER_DOTENV_KEY_PROD) {
                    throw new Error('u.envsInstallOrDecrypt: Missing `USER_DOTENV_KEY_PROD` environment variable.');
                }
                keys.push(env.USER_DOTENV_KEY_PROD);
            }
            await u.spawn(path.resolve(binDir, './envs.mjs'), ['decrypt', '--keys', ...keys]);
        } else {
            await u.spawn(path.resolve(binDir, './envs.mjs'), ['install']);
        }
    }

    static async loadEnv({ mode }) {
        const envFiles = await u.envFiles();

        if (!mode || 'main' === mode || !envFiles[mode]) {
            throw new Error('u.loadEnv: Invalid mode: `' + mode + '`.');
        }
        return $dotenv.parseExpand([envFiles.main, envFiles[mode]]);
    }

    static async _envsExtractKeys() {
        const keys = {}; // Initialize.
        const envFiles = await u.envFiles();

        u.log($chalk.gray('Extracting all Dotenv Vault keys.'));
        const output = await u.spawn('npx', ['dotenv-vault', 'keys', '--yes'], { quiet: true });

        let _m = null; // Initialize.
        const regExp = /\bdotenv:\/\/:key_.+?\?environment=([^\s]+)/giu;

        while ((_m = regExp.exec(output)) !== null) {
            keys[_m[1]] = _m[0];
        }
        if (Object.keys(keys).length !== Object.keys(envFiles).length) {
            throw new Error('u._envsExtractKeys: Failed to extract Dotenv Vault keys.');
        }
        return keys;
    }

    static async _envToJSON(envName, env) {
        let json = {}; // Initialize.

        for (let [name, value] of Object.entries(env)) {
            json[name] = String(value);
        }
        return $json.stringify(json, { pretty: true });
    }

    static async _envToProps(envName, env) {
        let props = '# ' + envName + '\n';

        for (let [name, value] of Object.entries(env)) {
            value = String(value);
            value = value.replace(/\r\n?/gu, '\n');
            value = value.replace(/\n/gu, '\\n');

            if (value.includes('\\n')) {
                // Dotenv evaulates newlines only if using double quotes.
                props += name + '=' + $str.quote(value, { type: 'double' }) + '\n';
            } else {
                props += name + '=' + $str.quote(value) + '\n'; // Single quotes.
            }
        }
        return props;
    }

    /*
     * NPM utilities.
     */

    static async isNPMPkg() {
        return (await u.isGitRepo()) && false === pkgPrivate;
    }

    static async isNPMPkgOriginNPMJS() {
        try {
            return (
                (await u.npmjsPkgOrigin()) && // Throws exception on failure.
                (await u.isNPMPkgRegistryNPMJS()) && // Confirms `https://registry.npmjs.org`.
                // This command throws an exception on failure; e.g., if package is not published at npmjs.
                (await u.spawn('npm', ['author', 'ls'], { quiet: true }).then(() => true)) // Published at npmjs?
            );
        } catch {
            return false;
        }
    }

    static async isNPMPkgRegistryNPMJS() {
        return await u.isNPMPkgRegistry('https://registry.npmjs.org');
    }

    static async isNPMPkgRegistry(registry) {
        return (
            registry.replace(/\/+$/, '') ===
            String(await u.spawn('npm', ['config', 'get', 'registry'], { quiet: true }))
                .trim()
                .replace(/\/+$/, '')
        );
    }

    static async isNPMPkgPublishable(opts = { mode: 'prod' }) {
        return (await u.isNPMPkg()) && 'main' === (await u.gitCurrentBranch()) && 'prod' === opts.mode;
    }

    static async npmInstall() {
        await u.spawn('npm', ['install'], { stdio: 'inherit' });
    }

    static async npmCleanInstall() {
        await u.spawn('npm', ['ci'], { stdio: 'inherit' });
    }

    static async npmUpdate(opts = { directive: 'default' }) {
        if ('no' === opts.directive /* NPM update skipped entirely. */) {
            u.log($chalk.gray('Skipping NPM update entirely.'));
        } else {
            if ('nimble' === opts.directive) {
                const pkg = await u.pkg(); // Package.
                let dependenciesToUpdate = []; // Initialize.

                for (const [dependency] of Object.entries(pkg.dependencies || {})) dependenciesToUpdate.push(dependency);
                for (const [dependency] of Object.entries(pkg.peerDependencies || {})) dependenciesToUpdate.push(dependency);
                if (!(await u.isPkgName('@clevercanyon/dev-deps')))
                    for (const [dependency] of Object.entries((await u.depPkg('@clevercanyon/dev-deps'))?.dependencies || {})) {
                        if (/^@clevercanyon\//iu.test(dependency)) dependenciesToUpdate.push(dependency);
                    }
                if (dependenciesToUpdate.length) {
                    dependenciesToUpdate = [...new Set(dependenciesToUpdate)];
                    u.log($chalk.gray('Updating these specific NPM dependencies:')), u.log($chalk.gray(dependenciesToUpdate.join(', ')));
                    await u.spawn('npm', ['update', ...dependenciesToUpdate, '--save'], { stdio: 'inherit' });
                }
                u.log($chalk.gray('Updating other NPM dependencies in `--prefer-offline` mode.'));
                await u.spawn('npm', ['update', '--prefer-offline', '--save'], { stdio: 'inherit' });
            } else {
                await u.spawn('npm', ['update', '--save'], { stdio: 'inherit' }); // Normal (full) NPM update.
            }
        }
        await u.updatePkg(); // To our standards.
    }

    static async npmPublish(opts = { dryRun: false }) {
        if (!opts.dryRun) {
            await u.spawn('npm', ['publish']);
        }
        if (await u.isNPMPkgOriginNPMJS()) {
            await u.npmjsCheckPkgOrgWideStandards({ dryRun: opts.dryRun });
        }
    }

    /*
     * npmjs utilities.
     */

    static async npmjsPkgOrigin() {
        let m = null; // Initialize array of matches.

        if ((m = /^(@[^/]+)\/([^/]+)$/iu.exec(pkgName))) {
            return { org: m[1], name: m[2] };
        } else if ((m = /^([^/]+)$/iu.exec(pkgName))) {
            return { org: '', name: m[1] };
        }
        throw new Error('u.npmjsPkgOrigin: Package does not have an npmjs origin.');
    }

    static async npmjsCheckPkgOrgWideStandards(opts = { dryRun: false }) {
        const { org } = await u.npmjsPkgOrigin();

        if ('@clevercanyon' !== org) {
            return; // Package not in the `@clevercanyon` organization.
        }
        if (!(await u._npmjsOrgUserCanAdmin(org))) {
            return; // Current user’s permissions do not allow package configuration.
        }
        const pkg = await u.pkg(); // Parses current `./package.json` file.

        if ($obp.get(pkg, 'config.c10n.&.npmjs.configVersions') === githubConfigVersion + ',' + npmjsConfigVersion) {
            u.log($chalk.gray('npmjs package configuration is up-to-date @v' + githubConfigVersion + ' @v' + npmjsConfigVersion + '.'));
            return; // Package configuration version is already up-to-date.
        }
        u.log($chalk.gray('Configuring npmjs package using org-wide standards.'));

        const teamsToDelete = await u._npmjsOrgTeams(org); // Current list of organization’s teams.
        const alwaysOnRequiredTeams = { developers: 'read-write', owners: 'read-write', 'security-managers': 'read-only' }; // No exceptions.

        const teams = $obj.assign({}, $obp.get(pkg, 'config.c10n.&.npmjs.teams', $obp.get(pkg, 'config.c10n.&.github.teams', {})), alwaysOnRequiredTeams);
        Object.keys(teams).forEach((team) => (teams[team] = /^(?:read-write|push|maintain|admin)$/iu.test(teams[team]) ? 'read-write' : 'read-only'));

        for (const [team, permission] of Object.entries(teams)) {
            delete teamsToDelete[team]; // Don't delete.

            u.log($chalk.gray('Adding `' + team + '` team to npmjs package with `' + permission + '` permission.'));
            if (!opts.dryRun) {
                await u.spawn('npm', ['access', 'grant', permission, org + ':' + team], { quiet: true });
            }
        }
        for (const [team] of Object.entries(teamsToDelete)) {
            u.log($chalk.gray('Deleting `' + team + '` (unused) from npmjs package.'));
            if (!opts.dryRun) {
                await u.spawn('npm', ['access', 'revoke', org + ':' + team], { quiet: true }).catch(() => null);
            }
        }
        if (!opts.dryRun) {
            await u.updatePkg('config.c10n.&.npmjs.configVersions', githubConfigVersion + ',' + npmjsConfigVersion);
        }
    }

    static async _npmjsOrgUserCanAdmin(org) {
        try {
            return $is.plainObject(await u._npmjsOrgUsers(org));
        } catch {
            return false; // Only admins|owners can list org members.
        }
    }

    static async _npmjsOrgUsers(org) {
        const members = $json.parse(String(await u.spawn('npm', ['org', 'ls', org, '--json'], { quiet: true })));

        if (!$is.plainObject(members)) {
            throw new Error('u._npmjsOrgMembers: Failed to acquire list of NPM team members for `' + org + '`.');
        }
        return members; // Keyed by username; values one of: `developer`, `admin`, or `owner`.
    }

    static async _npmjsOrgTeams(org) {
        const teams = $json.parse(String(await u.spawn('npm', ['team', 'ls', org, '--json'], { quiet: true })));

        if (!$is.array(teams)) {
            throw new Error('u._npmjsOrgTeams: Failed to acquire list of NPM teams for `' + org + '` org.');
        }
        return teams.reduce((obj, team) => {
            obj[team.replace(/^[^:]+:/u, '')] = team;
            return obj; // Object return.
        }, {});
    }

    /*
     * Vite utilities.
     */

    static async isViteBuild() {
        return '' !== pkgBuildAppType;
    }

    static async viteBuild(opts = { mode: 'prod' }) {
        await u.spawn('npx', ['vite', 'build', '--mode', opts.mode]);
    }

    /*
     * Dotfile utilities.
     */

    static async updateDotfiles() {
        await u.spawn('npx', ['@clevercanyon/madrun', 'update', 'dotfiles']);
    }

    /**
     * Finale utilities.
     */

    static async finaleBox(title, text) {
        return await $chalk.finaleBox(title, text, { image: c10nLogo });
    }
}
